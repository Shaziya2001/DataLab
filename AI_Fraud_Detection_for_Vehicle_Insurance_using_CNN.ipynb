{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Ripik.AI HackFest: Unleashing AI Potential**"
      ],
      "metadata": {
        "id": "QgWHHhuyMApj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI-Powered Fraud Detection for Vehicle Insurance Claims through DenseNet201 Model"
      ],
      "metadata": {
        "id": "WxLhqOKrMHVB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQifKXFnQ5dD"
      },
      "outputs": [],
      "source": [
        "#Importing the required libraries\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Ripik Hackathon Dataset/train.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('train')"
      ],
      "metadata": {
        "id": "ihQ5Nz-SREdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the training dataset\n",
        "train_df = pd.read_csv('/content/train/train/train.csv')"
      ],
      "metadata": {
        "id": "vWGmQ9fzRKKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Preprocessing\n",
        "image_size = (224, 224)\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "4rQqbBlERL_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the dataset into training and validation sets\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Zq15UQJURNbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the 'label' column to strings\n",
        "train_df['label'] = train_df['label'].astype(str)\n",
        "val_df['label'] = val_df['label'].astype(str)"
      ],
      "metadata": {
        "id": "TkznEClkRPRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating ImageDataGenerators for training and validation sets\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    directory='/content/train/train/images',\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    directory='/content/train/train/images',\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5qtIfLlRQqZ",
        "outputId": "02cc9fa9-8f5d-4fc7-8e02-116d570cfda3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5760 validated image filenames belonging to 6 classes.\n",
            "Found 1440 validated image filenames belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the DenseNet201 model pre-trained on ImageNet data\n",
        "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "#Freeze the pre-trained layers\n",
        "for layer in base_model.layers[-10:]:\n",
        "    layer.trainable = False\n",
        "#Building the model\n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(6, activation='softmax'))\n",
        "#Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizers.SGD(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "#Display the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arx327sjRS1O",
        "outputId": "7890fd66-1618-46d9-d650-e09103e08d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
            "                                                                 \n",
            " global_average_pooling2d_3  (None, 1920)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 11526     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18333510 (69.94 MB)\n",
            "Trainable params: 17818054 (67.97 MB)\n",
            "Non-trainable params: 515456 (1.97 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model training\n",
        "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=20,\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyWSBEnlRVaX",
        "outputId": "3ed88230-bc98-4d5a-f243-b59cfc7b7214"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.5731 - accuracy: 0.3142"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "360/360 [==============================] - 232s 455ms/step - loss: 1.5731 - accuracy: 0.3142 - val_loss: 1.4336 - val_accuracy: 0.3764\n",
            "Epoch 2/20\n",
            "360/360 [==============================] - 169s 469ms/step - loss: 1.3606 - accuracy: 0.4328 - val_loss: 1.2816 - val_accuracy: 0.4611\n",
            "Epoch 3/20\n",
            "360/360 [==============================] - 161s 448ms/step - loss: 1.2248 - accuracy: 0.5177 - val_loss: 1.1582 - val_accuracy: 0.5576\n",
            "Epoch 4/20\n",
            "360/360 [==============================] - 168s 467ms/step - loss: 1.1119 - accuracy: 0.5865 - val_loss: 1.0580 - val_accuracy: 0.6000\n",
            "Epoch 5/20\n",
            "360/360 [==============================] - 161s 447ms/step - loss: 1.0137 - accuracy: 0.6384 - val_loss: 0.9810 - val_accuracy: 0.6313\n",
            "Epoch 6/20\n",
            "360/360 [==============================] - 157s 436ms/step - loss: 0.9447 - accuracy: 0.6604 - val_loss: 0.9230 - val_accuracy: 0.6562\n",
            "Epoch 7/20\n",
            "360/360 [==============================] - 158s 439ms/step - loss: 0.8841 - accuracy: 0.6875 - val_loss: 0.8749 - val_accuracy: 0.6715\n",
            "Epoch 8/20\n",
            "360/360 [==============================] - 158s 437ms/step - loss: 0.8287 - accuracy: 0.7111 - val_loss: 0.8345 - val_accuracy: 0.6868\n",
            "Epoch 9/20\n",
            "360/360 [==============================] - 154s 429ms/step - loss: 0.7882 - accuracy: 0.7165 - val_loss: 0.7945 - val_accuracy: 0.6979\n",
            "Epoch 10/20\n",
            "360/360 [==============================] - 153s 425ms/step - loss: 0.7493 - accuracy: 0.7316 - val_loss: 0.7596 - val_accuracy: 0.7174\n",
            "Epoch 11/20\n",
            "360/360 [==============================] - 154s 428ms/step - loss: 0.7129 - accuracy: 0.7507 - val_loss: 0.7345 - val_accuracy: 0.7264\n",
            "Epoch 12/20\n",
            "360/360 [==============================] - 154s 427ms/step - loss: 0.6787 - accuracy: 0.7609 - val_loss: 0.7171 - val_accuracy: 0.7326\n",
            "Epoch 13/20\n",
            "360/360 [==============================] - 155s 431ms/step - loss: 0.6533 - accuracy: 0.7731 - val_loss: 0.6901 - val_accuracy: 0.7375\n",
            "Epoch 14/20\n",
            "360/360 [==============================] - 154s 427ms/step - loss: 0.6317 - accuracy: 0.7741 - val_loss: 0.6743 - val_accuracy: 0.7472\n",
            "Epoch 15/20\n",
            "360/360 [==============================] - 154s 428ms/step - loss: 0.6037 - accuracy: 0.7856 - val_loss: 0.6598 - val_accuracy: 0.7479\n",
            "Epoch 16/20\n",
            "360/360 [==============================] - 154s 428ms/step - loss: 0.5863 - accuracy: 0.7887 - val_loss: 0.6400 - val_accuracy: 0.7583\n",
            "Epoch 17/20\n",
            "360/360 [==============================] - 159s 442ms/step - loss: 0.5672 - accuracy: 0.7948 - val_loss: 0.6384 - val_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "360/360 [==============================] - 155s 429ms/step - loss: 0.5634 - accuracy: 0.7917 - val_loss: 0.6208 - val_accuracy: 0.7611\n",
            "Epoch 19/20\n",
            "360/360 [==============================] - 154s 427ms/step - loss: 0.5330 - accuracy: 0.8069 - val_loss: 0.6026 - val_accuracy: 0.7688\n",
            "Epoch 20/20\n",
            "360/360 [==============================] - 154s 427ms/step - loss: 0.5119 - accuracy: 0.8130 - val_loss: 0.5913 - val_accuracy: 0.7792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the test zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Ripik Hackathon Dataset/test.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('test')"
      ],
      "metadata": {
        "id": "5P7zB44IRZJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the trained model\n",
        "model = load_model('/content/best_model.h5')\n",
        "#Loading the testing dataset\n",
        "test_df = pd.read_csv('/content/test/test/test.csv')\n",
        "#Create a data generator for test data\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='filename',\n",
        "    y_col=None,\n",
        "    directory='/content/test/test/images',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=128,\n",
        "    class_mode=None,\n",
        "    shuffle=False\n",
        ")\n",
        "#Making predictions for the test set\n",
        "predictions = model.predict(test_generator)\n",
        "print(predictions)\n",
        "#Get the predicted labels\n",
        "predicted_labels = tf.argmax(predictions, axis=1).numpy() + 1\n",
        "#Creating a submission DataFrame\n",
        "submission_df = pd.DataFrame({'image_id': test_df['image_id'], 'label': predicted_labels})\n",
        "#Saving the submission DataFrame to a CSV file\n",
        "submission_df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1n-1Wmf6-tB",
        "outputId": "99260860-b631-48b2-d123-abd5bc81df28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4800 validated image filenames.\n",
            "38/38 [==============================] - 53s 1s/step\n",
            "[[5.24211898e-02 3.42505127e-01 2.90265027e-03 4.63463932e-01\n",
            "  6.78576343e-03 1.31921351e-01]\n",
            " [5.62954023e-02 5.77984512e-01 1.41354301e-03 2.86258996e-01\n",
            "  4.32597753e-03 7.37216324e-02]\n",
            " [1.14479195e-02 5.98866761e-01 1.31065748e-03 3.49064976e-01\n",
            "  1.86879584e-03 3.74409035e-02]\n",
            " ...\n",
            " [6.35236129e-02 7.57670879e-01 5.67723112e-03 7.78971165e-02\n",
            "  1.17049310e-02 8.35262313e-02]\n",
            " [8.72745179e-04 9.22450423e-01 2.05950477e-04 3.99663150e-02\n",
            "  2.61945184e-04 3.62425931e-02]\n",
            " [1.84447560e-02 3.21432874e-02 2.05048622e-04 9.18249846e-01\n",
            "  1.66653842e-03 2.92905439e-02]]\n"
          ]
        }
      ]
    }
  ]
}
